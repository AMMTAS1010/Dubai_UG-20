{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Delivery Dataset Analysis and CNN Model Training\n",
    "\n",
    "This notebook demonstrates the analysis of a food delivery dataset using various machine learning techniques. The notebook is divided into sections for data preprocessing, CNN model training, and analysis of the image dataset. You can choose between running a CNN model on an image dataset (Food101) or performing tabular analysis with Delivery or Restaurant datasets.\n",
    "\n",
    "### Table of Contents\n",
    "- **CNN Model Analysis for Food101 Dataset**: Training a pre-trained or custom CNN on the Food101 dataset.\n",
    "- **Tabular Dataset Analysis**: Analysis of the food delivery datasets using Logistic Regression or MLP classifiers.\n",
    "- **Image Size and Aspect Ratio Analysis**: Analyzing image sizes and aspect ratios for the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Analysis for Food101 Dataset\n",
    "\n",
    "This section demonstrates how to train a CNN model on the Food101 dataset. You can select between a pre-trained ResNet18 model or a custom-built classical CNN model.\n",
    "- The model will be trained using a set number of epochs. \n",
    "- The results include training accuracy and loss for each epoch and will be saved to a specified directory.\n",
    "\n",
    "Let's begin by setting up the parameters for the CNN model.\n",
    "- Run the following cell to train the model and display the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(dataset_path, meta_path, num_classes, img_height=224, img_width=224, batch_size=64, epochs=100, use_pretrained=True):\n",
    "    \"\"\"\n",
    "    Creates and trains a CNN model (ResNet18 or custom CNN) for food image classification.\n",
    "    \"\"\"\n",
    "    # Preprocessing and transformations for dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_height, img_width)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalizing for pre-trained models\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.ImageFolder(dataset_path, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Use pre-trained ResNet18 model if selected\n",
    "    if use_pretrained:\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)  # Change the final layer to match number of classes\n",
    "    else:\n",
    "        # Custom CNN model can be defined here (example)\n",
    "        model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * (img_height // 4) * (img_width // 4), num_classes)\n",
    "        )\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    epoch_accuracies = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct / total * 100\n",
    "        epoch_accuracies.append((epoch + 1, epoch_loss, epoch_accuracy))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    return epoch_accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now being trained on the Food101 dataset. Once you run the model training, the output will display the loss and accuracy for each epoch.\n",
    "\n",
    "Run the following cell to train the model and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to call the model training function\n",
    "dataset_path = \"../Datasets/archive/images\"\n",
    "meta_path = \"../Datasets/archive/meta/meta\"\n",
    "num_classes = 101  # Number of classes in Food101\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "epoch_accuracies = create_cnn_model(dataset_path, meta_path, num_classes, img_height, img_width, epochs=5)\n",
    "\n",
    "# Display results in a readable format\n",
    "epoch_df = pd.DataFrame(epoch_accuracies, columns=[\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "epoch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above table displays the training loss and accuracy for each epoch.**\n",
    "You can use this to monitor the model's performance during training.\n",
    "\n",
    "Let's now proceed to the tabular dataset analysis section.\n",
    "The table above displays the training loss and accuracy for each epoch during the CNN model training.\n",
    "\n",
    "Next, we will analyze the tabular food delivery datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing the datasets\n",
    "The below function loads and preprocesses the selected dataset (either Delivery or Restaurant). It splits the data into training and testing sets.\n",
    "\n",
    "Run the following cell to load and preprocess the data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(base_dir, dataset_type):\n",
    "    \"\"\"\n",
    "    Load the preprocessed data from the specified directory for the given dataset type.\n",
    "    \"\"\"\n",
    "    data_dir = os.path.join(base_dir, dataset_type)\n",
    "\n",
    "    X_train = pd.read_csv(os.path.join(data_dir, 'X_train.csv'))\n",
    "    y_train = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "    X_valid = pd.read_csv(os.path.join(data_dir, 'X_valid.csv'))\n",
    "    y_valid = pd.read_csv(os.path.join(data_dir, 'y_valid.csv'))\n",
    "    X_test = pd.read_csv(os.path.join(data_dir, 'X_test.csv'))\n",
    "    y_test = pd.read_csv(os.path.join(data_dir, 'y_test.csv'))\n",
    "\n",
    "    # Assuming 'target' column in y files\n",
    "    y_train = y_train['target']\n",
    "    y_valid = y_valid['target']\n",
    "    y_test = y_test['target']\n",
    "\n",
    "    # Combine training and validation sets\n",
    "    X_train_full = pd.concat([X_train, X_valid], axis=0)\n",
    "    y_train_full = pd.concat([y_train, y_valid], axis=0)\n",
    "\n",
    "    # Identify categorical features\n",
    "    categorical_features = X_train_full.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_features = [col for col in X_train_full.columns if col not in categorical_features]\n",
    "\n",
    "    num_classes = len(y_train_full.unique())\n",
    "\n",
    "    return X_train_full, y_train_full, X_test, y_test, num_classes, categorical_features, numerical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Dataset Analysis\n",
    "\n",
    "In this section, we will analyze the tabular datasets (Delivery or Restaurant) using machine learning classifiers. You can choose between Logistic Regression or MLP Classifier for the analysis. The results will be saved to the specified directory.\n",
    "\n",
    "Let's select the dataset and model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, feature_names, model_name, results_dir):\n",
    "    \"\"\"\n",
    "    Plot feature importance for Logistic Regression.\n",
    "    \"\"\"\n",
    "    # Get the coefficients from the logistic regression model\n",
    "    coef = model.named_steps['classifier'].coef_\n",
    "\n",
    "    # Get feature names after preprocessing\n",
    "    preprocessor = model.named_steps['preprocessor']\n",
    "    feature_names_transformed = preprocessor.get_feature_names_out()\n",
    "\n",
    "    # Create a DataFrame for coefficients\n",
    "    coef_df = pd.DataFrame(coef.T, index=feature_names_transformed, columns=model.named_steps['classifier'].classes_)\n",
    "\n",
    "    # Plot the coefficients\n",
    "    for class_label in model.named_steps['classifier'].classes_:\n",
    "        top_features = coef_df[class_label].abs().sort_values(ascending=False).head(10)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x=top_features.values, y=top_features.index)\n",
    "        plt.title(f\"Top Features for Class {class_label}\")\n",
    "        plt.xlabel(\"Coefficient Value\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f\"{model_name}_Feature_Importance_Class_{class_label}.png\"))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_logistic_regression(model, param_grid, X_train, X_test, y_train, y_test, model_name, class_labels, results_dir):\n",
    "    print(f\"\\nEvaluating {model_name}\")\n",
    "\n",
    "    # Grid Search with Cross-Validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Save cross-validation results\n",
    "    cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "    cv_results.to_csv(os.path.join(results_dir, f\"{model_name}_grid_search_results.csv\"), index=False)\n",
    "\n",
    "    # Predict and evaluate on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Ensure class_labels are strings\n",
    "    class_labels_str = [str(label) for label in class_labels]\n",
    "\n",
    "    report = classification_report(y_test, y_pred, target_names=class_labels_str)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Save classification report to a text file\n",
    "    with open(os.path.join(results_dir, f\"{model_name}_classification_report.txt\"), \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        conf_matrix,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_labels_str,\n",
    "        yticklabels=class_labels_str\n",
    "    )\n",
    "    plt.title(f\"{model_name} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.savefig(os.path.join(results_dir, f\"{model_name}_confusion_matrix.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    # Learning Curve\n",
    "    plot_learning_curve(best_model, X_train, y_train, model_name, results_dir)\n",
    "\n",
    "    # Feature Importance\n",
    "    plot_feature_importance(best_model, X_train.columns, model_name, results_dir)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(model, X_test, y_test, model_name, num_classes, results_dir):\n",
    "    \"\"\"\n",
    "    Plot the ROC curve for multiclass classification.\n",
    "    \"\"\"\n",
    "    # Binarize the output for multiclass\n",
    "    classes = np.unique(y_test)\n",
    "    y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "    # Get probabilities\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_prob = model.decision_function(X_test)\n",
    "    else:\n",
    "        print(\"Model does not support probability predictions.\")\n",
    "        return\n",
    "\n",
    "    # Plot ROC curve for each class\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    for idx, class_label in enumerate(classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, idx], y_prob[:, idx])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"Class {class_label} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "    plt.title(f\"{model_name} ROC Curve (Multiclass)\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(results_dir, f\"{model_name}_ROC_curve.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_pytorch(X_train, y_train, X_test, y_test, num_classes, results_dir, class_labels):\n",
    "    # Encode categorical variables\n",
    "    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    # One-Hot Encoding for categorical features\n",
    "    if version.parse(sklearn.__version__) >= version.parse(\"1.2\"):\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    else:\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    X_train_cat = encoder.fit_transform(X_train[categorical_cols])\n",
    "    X_test_cat = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "    # Standardization for numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_num = scaler.fit_transform(X_train[numerical_cols])\n",
    "    X_test_num = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "    # Combine numerical and categorical features\n",
    "    X_train_processed = np.hstack([X_train_num, X_train_cat])\n",
    "    X_test_processed = np.hstack([X_test_num, X_test_cat])\n",
    "\n",
    "    # Encode target variable\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_processed, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long).to(device)\n",
    "\n",
    "    # Define model parameters\n",
    "    input_size = X_train_processed.shape[1]\n",
    "    hidden_sizes = [128, 64]\n",
    "    model = MLPClassifierTorch(input_size, hidden_sizes, num_classes).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 50\n",
    "    batch_size = 64\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs_batch, labels_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            loss = criterion(outputs, labels_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs_batch.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels_batch.size(0)\n",
    "            correct += (predicted == labels_batch).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = correct / total\n",
    "        train_acc_history.append(epoch_acc)\n",
    "\n",
    "        # Validation accuracy\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_test_tensor)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = y_test_tensor.size(0)\n",
    "            correct = (predicted == y_test_tensor).sum().item()\n",
    "            val_acc = correct / total\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), os.path.join(results_dir, 'MLPClassifier_PyTorch.pth'))\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(range(1, num_epochs+1), train_acc_history, label='Training Accuracy')\n",
    "    plt.plot(range(1, num_epochs+1), val_acc_history, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy for MLP Classifier')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(results_dir, 'MLPClassifier_Accuracy.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred = predicted.cpu().numpy()\n",
    "        y_true = y_test_encoded\n",
    "\n",
    "    # Ensure class_labels are strings\n",
    "    class_labels_str = [str(label) for label in class_labels]\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=class_labels_str)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Save classification report to a text file\n",
    "    with open(os.path.join(results_dir, \"MLPClassifier_classification_report.txt\"), \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        conf_matrix,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_labels_str,\n",
    "        yticklabels=class_labels_str\n",
    "    )\n",
    "    plt.title(\"MLP Classifier Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.savefig(os.path.join(results_dir, \"MLPClassifier_confusion_matrix.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tabular_analysis():\n",
    "    \"\"\"\n",
    "    Runs the tabular data analysis for Delivery or Restaurant datasets.\n",
    "    \"\"\"\n",
    "    print(\"Select Dataset Type:\")\n",
    "    print(\"1. Delivery Dataset\")\n",
    "    print(\"2. Restaurant Dataset\")\n",
    "    dataset_choice = input(\"Enter the dataset number (1 or 2): \")\n",
    "\n",
    "    if dataset_choice == \"1\":\n",
    "        dataset_type = \"delivery\"\n",
    "        dataset_name = \"Delivery\"\n",
    "    elif dataset_choice == \"2\":\n",
    "        dataset_type = \"restaurant\"\n",
    "        dataset_name = \"Restaurant\"\n",
    "    else:\n",
    "        print(\"Invalid dataset choice.\")\n",
    "        return\n",
    "\n",
    "    base_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'Datasets', 'preprocessed_data'))\n",
    "\n",
    "    # Load and preprocess data\n",
    "    X_train_full, y_train_full, X_test, y_test, num_classes, categorical_features, numerical_features = load_and_preprocess_data(base_dir, dataset_type)\n",
    "\n",
    "    print(\"\\nSelect Model:\")\n",
    "    print(\"1. Logistic Regression\")\n",
    "    print(\"2. MLP Classifier\")\n",
    "    model_choice = input(\"Enter the model number (1 or 2): \")\n",
    "\n",
    "    # Get class labels for plotting\n",
    "    class_labels = sorted(y_train_full.unique())\n",
    "    class_labels_str = [str(label) for label in class_labels]  # Convert to strings\n",
    "\n",
    "    # Create results directory\n",
    "    if model_choice == \"1\":\n",
    "        model_name = \"LogisticRegression\"\n",
    "    elif model_choice == \"2\":\n",
    "        model_name = \"MLPClassifier_PyTorch\"\n",
    "    else:\n",
    "        print(\"Invalid model choice.\")\n",
    "        return\n",
    "\n",
    "    results_dir = f\"Results/{model_name}_{dataset_name}\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    if model_choice == \"1\":\n",
    "        # Logistic Regression\n",
    "        model = create_logistic_regression_pipeline(categorical_features, numerical_features)\n",
    "\n",
    "        # Define hyperparameter grid for Logistic Regression\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10],\n",
    "            'classifier__penalty': ['l2'],\n",
    "            'classifier__solver': ['lbfgs', 'saga', 'sag'],\n",
    "            'classifier__max_iter': [500, 1000]\n",
    "        }\n",
    "\n",
    "        print(\"\\nStarting Logistic Regression training and evaluation...\")\n",
    "        # Evaluate Logistic Regression\n",
    "        best_model = evaluate_logistic_regression(\n",
    "            model,\n",
    "            param_grid,\n",
    "            X_train_full,\n",
    "            X_test,\n",
    "            y_train_full,\n",
    "            y_test,\n",
    "            model_name,\n",
    "            class_labels_str,  # Use string labels\n",
    "            results_dir\n",
    "        )\n",
    "\n",
    "        # Plot ROC Curve\n",
    "        plot_roc_curve(best_model, X_test, y_test, model_name, num_classes, results_dir)\n",
    "\n",
    "    elif model_choice == \"2\":\n",
    "        # MLP Classifier using PyTorch\n",
    "\n",
    "        print(\"\\nStarting MLP Classifier training and evaluation...\")\n",
    "        # Train and evaluate MLP Classifier\n",
    "        train_mlp_pytorch(\n",
    "            X_train_full,\n",
    "            y_train_full,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            num_classes,\n",
    "            results_dir,\n",
    "            class_labels_str  # Use string labels\n",
    "        )\n",
    "    else:\n",
    "        print(\"Invalid model choice.\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample data has been loaded and preprocessed. You can now proceed with training a model on this data.\n",
    "\n",
    "The following cell will evaluate a Logistic Regression model with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_logistic_regression(model, param_grid, X_train, X_test, y_train, y_test, model_name, class_labels):\n",
    "    \"\"\"\n",
    "    Evaluates the logistic regression model on the dataset using hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Best Model: {grid_search.best_params_}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now run the `evaluate_logistic_regression()` function to train and evaluate a Logistic Regression model on the preprocessed food delivery dataset.\n",
    "\n",
    "Once the model finishes, the evaluation results will display the best hyperparameters and the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to call the logistic regression evaluation function\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10]}  # Hyperparameter grid for regularization strength\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model_name = 'Logistic Regression'\n",
    "\n",
    "best_model = evaluate_logistic_regression(model, param_grid, X_train, X_test, y_train, y_test, model_name, class_labels=['Class 0', 'Class 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Size and Aspect Ratio Analysis\n",
    "\n",
    "In this section, we'll analyze the image sizes and aspect ratios in a given dataset directory. \n",
    "- It calculates the frequencies of different sizes and aspect ratios and displays a plot of the distribution.\n",
    "- The function will provide a summary of image sizes and aspect ratios, and also plot their distribution.\n",
    "\n",
    "Let's proceed with the image size analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_sizes(root_dir, extensions={'jpg', 'jpeg', 'png', 'bmp', 'gif'}):\n",
    "    \"\"\"\n",
    "    Analyzes the sizes and aspect ratios of the images in the dataset directory.\n",
    "    \"\"\"\n",
    "    aspect_ratios = defaultdict(int)\n",
    "    image_sizes = defaultdict(int)\n",
    "\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.split('.')[-1].lower() in extensions:\n",
    "                image_path = os.path.join(root, file)\n",
    "                img = Image.open(image_path)\n",
    "                width, height = img.size\n",
    "\n",
    "                aspect_ratio = width / height\n",
    "                image_sizes[(width, height)] += 1\n",
    "                aspect_ratios[aspect_ratio] += 1\n",
    "\n",
    "    return image_sizes, aspect_ratios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function will analyze the sizes and aspect ratios of images in the specified dataset directory. You can run it to inspect the distribution of image dimensions.\n",
    "\n",
    "Once the analysis is complete, the results will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Sizes Distribution: defaultdict(<class 'int'>, {(512, 342): 359, (512, 384): 14791, (512, 512): 62206, (512, 382): 2512, (384, 512): 6518, (512, 289): 911, (382, 512): 2879, (512, 341): 1508, (373, 512): 2, (512, 307): 371, (512, 340): 383, (341, 512): 251, (512, 314): 4, (342, 512): 52, (512, 385): 101, (512, 304): 37, (512, 485): 5, (512, 288): 890, (512, 360): 7, (512, 511): 270, (287, 512): 77, (306, 512): 504, (289, 512): 290, (512, 343): 183, (512, 305): 4, (512, 366): 41, (512, 308): 82, (512, 381): 26, (304, 512): 13, (512, 463): 10, (511, 512): 543, (512, 383): 454, (512, 369): 11, (512, 306): 1031, (512, 403): 9, (512, 462): 2, (512, 410): 34, (339, 512): 29, (512, 481): 5, (512, 313): 5, (512, 296): 4, (512, 328): 6, (512, 252): 3, (512, 352): 7, (512, 405): 8, (512, 333): 17, (506, 512): 25, (466, 512): 4, (468, 512): 5, (512, 335): 7, (288, 512): 255, (383, 512): 210, (512, 287): 220, (512, 346): 14, (512, 396): 8, (512, 339): 151, (512, 437): 2, (307, 512): 132, (505, 512): 6, (512, 500): 44, (512, 470): 15, (512, 312): 6, (512, 394): 9, (512, 400): 8, (512, 338): 6, (512, 471): 34, (404, 512): 6, (512, 509): 85, (512, 345): 6, (512, 295): 5, (512, 356): 7, (512, 417): 7, (512, 508): 35, (512, 441): 6, (308, 512): 36, (512, 390): 11, (512, 510): 42, (512, 298): 6, (359, 512): 3, (512, 230): 1, (512, 498): 10, (512, 386): 30, (512, 497): 10, (512, 226): 2, (410, 512): 20, (512, 375): 8, (512, 388): 17, (512, 297): 1, (512, 501): 9, (512, 266): 1, (512, 380): 18, (512, 257): 1, (512, 413): 4, (512, 465): 7, (512, 358): 10, (344, 512): 6, (512, 438): 9, (343, 512): 21, (358, 512): 3, (378, 512): 7, (512, 506): 30, (512, 378): 13, (496, 512): 4, (385, 512): 33, (445, 512): 10, (508, 512): 38, (512, 291): 5, (512, 507): 15, (340, 512): 40, (512, 309): 5, (509, 512): 32, (512, 452): 5, (512, 494): 9, (512, 478): 10, (512, 418): 7, (512, 351): 5, (376, 512): 3, (392, 512): 4, (510, 512): 66, (512, 320): 11, (512, 348): 13, (390, 512): 3, (512, 392): 12, (512, 344): 33, (403, 512): 5, (480, 512): 5, (512, 409): 9, (512, 285): 3, (512, 414): 3, (512, 504): 17, (379, 512): 8, (512, 484): 9, (298, 512): 1, (471, 512): 4, (512, 496): 10, (512, 406): 3, (512, 439): 5, (512, 474): 10, (512, 391): 8, (493, 512): 4, (512, 486): 6, (512, 389): 10, (512, 420): 7, (512, 353): 7, (512, 359): 6, (512, 362): 10, (484, 512): 2, (512, 310): 8, (512, 450): 4, (512, 489): 9, (512, 491): 9, (512, 326): 9, (512, 425): 4, (512, 487): 15, (365, 512): 4, (512, 324): 12, (351, 512): 2, (512, 393): 8, (391, 512): 4, (426, 512): 12, (428, 512): 5, (512, 444): 3, (483, 512): 4, (432, 512): 2, (333, 512): 8, (512, 377): 15, (482, 512): 4, (439, 512): 2, (487, 512): 4, (464, 512): 3, (512, 372): 17, (348, 512): 1, (512, 322): 4, (374, 512): 2, (408, 512): 4, (512, 273): 3, (357, 512): 3, (512, 492): 11, (512, 395): 9, (425, 512): 6, (388, 512): 5, (512, 355): 10, (512, 371): 5, (349, 512): 2, (512, 456): 9, (512, 499): 16, (512, 330): 5, (329, 512): 3, (512, 398): 9, (512, 374): 12, (452, 512): 2, (512, 453): 8, (512, 431): 6, (512, 334): 11, (512, 435): 6, (512, 404): 6, (512, 475): 6, (467, 512): 3, (324, 512): 1, (512, 303): 2, (415, 512): 4, (512, 325): 6, (438, 512): 4, (512, 493): 9, (512, 461): 8, (456, 512): 3, (512, 294): 12, (320, 512): 2, (504, 512): 4, (386, 512): 11, (512, 443): 8, (301, 512): 6, (512, 357): 7, (429, 512): 2, (512, 505): 18, (512, 331): 3, (512, 424): 3, (512, 455): 5, (512, 363): 7, (512, 236): 3, (512, 433): 5, (512, 271): 3, (512, 315): 3, (444, 512): 5, (512, 490): 9, (512, 337): 10, (512, 416): 7, (319, 512): 2, (490, 512): 4, (512, 300): 5, (440, 512): 7, (512, 412): 7, (498, 512): 2, (512, 460): 7, (512, 402): 5, (407, 512): 1, (458, 512): 4, (512, 281): 2, (512, 399): 4, (512, 332): 16, (512, 290): 2, (512, 421): 7, (472, 512): 2, (345, 512): 2, (512, 482): 9, (381, 512): 13, (460, 512): 2, (512, 379): 20, (455, 512): 2, (499, 512): 5, (446, 512): 4, (512, 449): 9, (512, 387): 13, (503, 512): 4, (512, 436): 5, (512, 354): 11, (512, 407): 8, (512, 364): 6, (512, 262): 2, (442, 512): 13, (512, 442): 10, (512, 502): 10, (512, 254): 3, (512, 428): 6, (453, 512): 2, (512, 503): 14, (512, 286): 7, (507, 512): 19, (512, 321): 6, (512, 446): 5, (328, 512): 2, (474, 512): 3, (512, 432): 7, (485, 512): 2, (512, 373): 5, (413, 512): 2, (512, 349): 10, (512, 293): 2, (512, 318): 3, (512, 376): 9, (380, 512): 7, (294, 512): 1, (512, 256): 3, (435, 512): 4, (377, 512): 2, (512, 429): 4, (512, 426): 6, (512, 476): 3, (512, 451): 2, (512, 448): 4, (449, 512): 1, (443, 512): 4, (512, 464): 6, (396, 512): 2, (512, 408): 6, (512, 365): 6, (338, 512): 1, (512, 473): 4, (462, 512): 1, (512, 317): 7, (512, 316): 7, (512, 336): 7, (417, 512): 1, (414, 512): 2, (419, 512): 2, (412, 512): 4, (512, 222): 2, (375, 512): 5, (502, 512): 6, (512, 361): 7, (512, 367): 6, (512, 472): 5, (512, 347): 6, (327, 512): 1, (512, 440): 4, (512, 276): 3, (512, 423): 6, (463, 512): 2, (512, 445): 9, (512, 259): 1, (512, 319): 10, (479, 512): 2, (512, 430): 4, (512, 447): 4, (401, 512): 1, (512, 477): 13, (512, 370): 10, (488, 512): 1, (512, 469): 3, (512, 468): 4, (330, 512): 1, (312, 512): 1, (332, 512): 6, (354, 512): 3, (512, 488): 6, (512, 282): 2, (420, 512): 5, (512, 483): 6, (512, 182): 1, (491, 512): 2, (512, 457): 4, (512, 229): 1, (447, 512): 1, (512, 401): 8, (454, 512): 2, (512, 253): 1, (486, 512): 2, (512, 329): 8, (387, 512): 3, (346, 512): 4, (512, 350): 4, (512, 419): 3, (418, 512): 4, (512, 368): 4, (512, 479): 12, (389, 512): 5, (512, 299): 3, (512, 292): 4, (411, 512): 3, (451, 512): 5, (500, 512): 4, (512, 434): 7, (394, 512): 2, (512, 249): 2, (350, 512): 1, (433, 512): 4, (405, 512): 1, (512, 301): 8, (469, 512): 1, (450, 512): 4, (477, 512): 5, (512, 188): 1, (512, 302): 3, (512, 269): 2, (512, 427): 4, (416, 512): 1, (512, 495): 3, (512, 411): 5, (489, 512): 2, (512, 280): 1, (397, 512): 1, (368, 512): 1, (395, 512): 1, (512, 268): 3, (512, 480): 7, (193, 512): 1, (512, 458): 2, (512, 467): 5, (492, 512): 1, (465, 512): 2, (512, 459): 7, (302, 512): 1, (366, 512): 5, (400, 512): 2, (356, 512): 2, (512, 165): 1, (457, 512): 3, (399, 512): 2, (398, 512): 2, (475, 512): 2, (427, 512): 3, (512, 213): 1, (296, 512): 1, (512, 122): 1, (512, 272): 1, (512, 232): 1, (512, 466): 3, (470, 512): 3, (242, 512): 1, (393, 512): 2, (316, 512): 1, (512, 241): 3, (512, 225): 1, (501, 512): 4, (512, 283): 1, (497, 512): 1, (512, 454): 3, (512, 220): 1, (448, 512): 1, (512, 275): 2, (512, 231): 2, (512, 323): 2, (512, 277): 2, (512, 311): 1, (430, 512): 1, (512, 260): 2, (512, 397): 4, (512, 327): 1, (512, 210): 1, (459, 512): 1, (437, 512): 1, (322, 512): 1, (361, 512): 1, (512, 415): 5, (512, 140): 1, (331, 512): 2, (370, 512): 1, (512, 274): 1, (512, 265): 1, (423, 512): 2, (512, 422): 4, (367, 512): 1, (494, 512): 1, (409, 512): 2, (424, 512): 2, (402, 512): 1, (371, 512): 1, (512, 284): 2, (279, 512): 1, (512, 218): 1, (512, 243): 1, (512, 181): 1, (512, 278): 2, (512, 239): 2, (512, 246): 1, (512, 247): 1, (406, 512): 1, (323, 512): 1, (421, 512): 2, (512, 228): 1, (325, 512): 1, (223, 512): 1, (431, 512): 2, (512, 267): 1})\n",
      "Aspect Ratios Distribution: defaultdict(<class 'int'>, {1.4970760233918128: 359, 1.3333333333333333: 14791, 1.0: 62206, 1.3403141361256545: 2512, 0.75: 6518, 1.7716262975778547: 911, 0.74609375: 2879, 1.501466275659824: 1508, 0.728515625: 2, 1.6677524429967427: 371, 1.5058823529411764: 383, 0.666015625: 251, 1.6305732484076434: 4, 0.66796875: 52, 1.3298701298701299: 101, 1.6842105263157894: 37, 1.0556701030927835: 5, 1.7777777777777777: 890, 1.4222222222222223: 7, 1.0019569471624266: 270, 0.560546875: 77, 0.59765625: 504, 0.564453125: 290, 1.4927113702623906: 183, 1.678688524590164: 4, 1.3989071038251366: 41, 1.6623376623376624: 82, 1.3438320209973753: 26, 0.59375: 13, 1.1058315334773219: 10, 0.998046875: 543, 1.3368146214099217: 454, 1.3875338753387534: 11, 1.673202614379085: 1031, 1.2704714640198511: 9, 1.1082251082251082: 2, 1.248780487804878: 34, 0.662109375: 29, 1.0644490644490645: 5, 1.6357827476038338: 5, 1.7297297297297298: 4, 1.5609756097560976: 6, 2.0317460317460316: 3, 1.4545454545454546: 7, 1.2641975308641975: 8, 1.5375375375375375: 17, 0.98828125: 25, 0.91015625: 4, 0.9140625: 5, 1.528358208955224: 7, 0.5625: 255, 0.748046875: 210, 1.78397212543554: 220, 1.4797687861271676: 14, 1.292929292929293: 8, 1.5103244837758112: 151, 1.17162471395881: 2, 0.599609375: 132, 0.986328125: 6, 1.024: 44, 1.0893617021276596: 15, 1.641025641025641: 6, 1.299492385786802: 9, 1.28: 8, 1.514792899408284: 6, 1.0870488322717622: 34, 0.7890625: 6, 1.005893909626719: 85, 1.4840579710144928: 6, 1.735593220338983: 5, 1.4382022471910112: 7, 1.2278177458033572: 7, 1.0078740157480315: 35, 1.1609977324263039: 6, 0.6015625: 36, 1.3128205128205128: 11, 1.003921568627451: 42, 1.7181208053691275: 6, 0.701171875: 3, 2.226086956521739: 1, 1.0281124497991967: 10, 1.3264248704663213: 30, 1.0301810865191148: 10, 2.265486725663717: 2, 0.80078125: 20, 1.3653333333333333: 8, 1.3195876288659794: 17, 1.7239057239057238: 1, 1.0219560878243512: 9, 1.9248120300751879: 1, 1.3473684210526315: 18, 1.9922178988326849: 1, 1.2397094430992737: 4, 1.1010752688172043: 7, 1.4301675977653632: 10, 0.671875: 6, 1.1689497716894977: 9, 0.669921875: 21, 0.69921875: 3, 0.73828125: 7, 1.0118577075098814: 30, 1.3544973544973544: 13, 0.96875: 4, 0.751953125: 33, 0.869140625: 10, 0.9921875: 38, 1.7594501718213058: 5, 1.009861932938856: 15, 0.6640625: 40, 1.656957928802589: 5, 0.994140625: 32, 1.1327433628318584: 5, 1.0364372469635628: 9, 1.0711297071129706: 10, 1.2248803827751196: 7, 1.4586894586894588: 5, 0.734375: 3, 0.765625: 4, 0.99609375: 66, 1.6: 11, 1.471264367816092: 13, 0.76171875: 3, 1.3061224489795917: 12, 1.4883720930232558: 33, 0.787109375: 5, 0.9375: 5, 1.2518337408312958: 9, 1.7964912280701755: 3, 1.2367149758454106: 3, 1.0158730158730158: 17, 0.740234375: 8, 1.0578512396694215: 9, 0.58203125: 1, 0.919921875: 4, 1.032258064516129: 10, 1.2610837438423645: 3, 1.1662870159453302: 5, 1.080168776371308: 10, 1.3094629156010231: 8, 0.962890625: 4, 1.0534979423868314: 6, 1.3161953727506426: 10, 1.2190476190476192: 7, 1.4504249291784703: 7, 1.426183844011142: 6, 1.4143646408839778: 10, 0.9453125: 2, 1.6516129032258065: 8, 1.1377777777777778: 4, 1.047034764826176: 9, 1.0427698574338085: 9, 1.5705521472392638: 9, 1.204705882352941: 4, 1.051334702258727: 15, 0.712890625: 4, 1.5802469135802468: 12, 0.685546875: 2, 1.3027989821882953: 8, 0.763671875: 4, 0.83203125: 12, 0.8359375: 5, 1.1531531531531531: 3, 0.943359375: 4, 0.84375: 2, 0.650390625: 8, 1.3580901856763925: 15, 0.94140625: 4, 0.857421875: 2, 0.951171875: 4, 0.90625: 3, 1.3763440860215055: 17, 0.6796875: 1, 1.5900621118012421: 4, 0.73046875: 2, 0.796875: 4, 1.8754578754578755: 3, 0.697265625: 3, 1.0406504065040652: 11, 1.2962025316455696: 9, 0.830078125: 6, 0.7578125: 5, 1.4422535211267606: 10, 1.3800539083557952: 5, 0.681640625: 2, 1.1228070175438596: 9, 1.0260521042084167: 16, 1.5515151515151515: 5, 0.642578125: 3, 1.2864321608040201: 9, 1.3689839572192513: 12, 0.8828125: 2, 1.130242825607064: 8, 1.1879350348027842: 6, 1.532934131736527: 11, 1.1770114942528735: 6, 1.2673267326732673: 6, 1.0778947368421052: 6, 0.912109375: 3, 0.6328125: 1, 1.6897689768976898: 2, 0.810546875: 4, 1.5753846153846154: 6, 0.85546875: 4, 1.0385395537525355: 9, 1.1106290672451193: 8, 0.890625: 3, 1.7414965986394557: 12, 0.625: 2, 0.984375: 4, 0.75390625: 11, 1.1557562076749435: 8, 0.587890625: 6, 1.4341736694677871: 7, 0.837890625: 2, 1.0138613861386139: 18, 1.5468277945619335: 3, 1.2075471698113207: 3, 1.1252747252747253: 5, 1.4104683195592287: 7, 2.169491525423729: 3, 1.1824480369515011: 5, 1.8892988929889298: 3, 1.6253968253968254: 3, 0.8671875: 5, 1.0448979591836736: 9, 1.5192878338278932: 10, 1.2307692307692308: 7, 0.623046875: 2, 0.95703125: 4, 1.7066666666666668: 5, 0.859375: 7, 1.2427184466019416: 7, 0.97265625: 2, 1.1130434782608696: 7, 1.2736318407960199: 5, 0.794921875: 1, 0.89453125: 4, 1.8220640569395017: 2, 1.2832080200501252: 4, 1.5421686746987953: 16, 1.7655172413793103: 2, 1.2161520190023754: 7, 0.921875: 2, 0.673828125: 2, 1.062240663900415: 9, 0.744140625: 13, 0.8984375: 2, 1.3509234828496042: 20, 0.888671875: 2, 0.974609375: 5, 0.87109375: 4, 1.1403118040089086: 9, 1.322997416020672: 13, 0.982421875: 4, 1.1743119266055047: 5, 1.4463276836158192: 11, 1.257985257985258: 8, 1.4065934065934067: 6, 1.9541984732824427: 2, 0.86328125: 13, 1.158371040723982: 10, 1.0199203187250996: 10, 2.015748031496063: 3, 1.1962616822429906: 6, 0.884765625: 2, 1.0178926441351888: 14, 1.7902097902097902: 7, 0.990234375: 19, 1.5950155763239875: 6, 1.147982062780269: 5, 0.640625: 2, 0.92578125: 3, 1.1851851851851851: 7, 0.947265625: 2, 1.3726541554959786: 5, 0.806640625: 2, 1.4670487106017192: 10, 1.7474402730375427: 2, 1.610062893081761: 3, 1.3617021276595744: 9, 0.7421875: 7, 0.57421875: 1, 2.0: 3, 0.849609375: 4, 0.736328125: 2, 1.1934731934731935: 4, 1.2018779342723005: 6, 1.0756302521008403: 3, 1.1352549889135255: 2, 1.1428571428571428: 4, 0.876953125: 1, 0.865234375: 4, 1.103448275862069: 6, 0.7734375: 2, 1.2549019607843137: 6, 1.4027397260273973: 6, 0.66015625: 1, 1.0824524312896406: 4, 0.90234375: 1, 1.615141955835962: 7, 1.620253164556962: 7, 1.5238095238095237: 7, 0.814453125: 1, 0.80859375: 2, 0.818359375: 2, 0.8046875: 4, 2.3063063063063063: 2, 0.732421875: 5, 0.98046875: 6, 1.4182825484764543: 7, 1.3950953678474114: 6, 1.0847457627118644: 5, 1.4755043227665705: 6, 0.638671875: 1, 1.1636363636363636: 4, 1.855072463768116: 3, 1.210401891252955: 6, 0.904296875: 2, 1.150561797752809: 9, 1.9768339768339769: 1, 1.6050156739811912: 10, 0.935546875: 2, 1.1906976744186046: 4, 1.145413870246085: 4, 0.783203125: 1, 1.0733752620545074: 13, 1.3837837837837839: 10, 0.953125: 1, 1.091684434968017: 3, 1.0940170940170941: 4, 0.64453125: 1, 0.609375: 1, 0.6484375: 6, 0.69140625: 3, 1.0491803278688525: 6, 1.8156028368794326: 2, 0.8203125: 5, 1.060041407867495: 6, 2.8131868131868134: 1, 0.958984375: 2, 1.1203501094091903: 4, 2.2358078602620086: 1, 0.873046875: 1, 1.2768079800498753: 8, 0.88671875: 2, 2.0237154150197627: 1, 0.94921875: 2, 1.5562310030395137: 8, 0.755859375: 3, 0.67578125: 4, 1.4628571428571429: 4, 1.2219570405727924: 3, 0.81640625: 4, 1.391304347826087: 4, 1.068893528183716: 12, 0.759765625: 5, 1.7123745819397993: 3, 1.7534246575342465: 4, 0.802734375: 3, 0.880859375: 5, 0.9765625: 4, 1.1797235023041475: 7, 0.76953125: 2, 2.0562248995983934: 2, 0.68359375: 1, 0.845703125: 4, 0.791015625: 1, 1.7009966777408638: 8, 0.916015625: 1, 0.87890625: 4, 0.931640625: 5, 2.723404255319149: 1, 1.695364238410596: 3, 1.903345724907063: 2, 1.199063231850117: 4, 0.8125: 1, 1.0343434343434343: 3, 1.245742092457421: 5, 0.955078125: 2, 1.8285714285714285: 1, 0.775390625: 1, 0.71875: 1, 0.771484375: 1, 1.9104477611940298: 3, 1.0666666666666667: 7, 0.376953125: 1, 1.1179039301310043: 2, 1.0963597430406853: 5, 0.9609375: 1, 0.908203125: 2, 1.1154684095860568: 7, 0.58984375: 1, 0.71484375: 5, 0.78125: 2, 0.6953125: 2, 3.103030303030303: 1, 0.892578125: 3, 0.779296875: 2, 0.77734375: 2, 0.927734375: 2, 0.833984375: 3, 2.403755868544601: 1, 0.578125: 1, 4.19672131147541: 1, 1.8823529411764706: 1, 2.206896551724138: 1, 1.0987124463519313: 3, 0.91796875: 3, 0.47265625: 1, 0.767578125: 2, 0.6171875: 1, 2.12448132780083: 3, 2.2755555555555556: 1, 0.978515625: 4, 1.8091872791519434: 1, 0.970703125: 1, 1.1277533039647578: 3, 2.327272727272727: 1, 0.875: 1, 1.8618181818181818: 2, 2.2164502164502164: 2, 1.585139318885449: 2, 1.848375451263538: 2, 1.6463022508038585: 1, 0.83984375: 1, 1.9692307692307693: 2, 1.2896725440806045: 4, 1.5657492354740061: 1, 2.4380952380952383: 1, 0.896484375: 1, 0.853515625: 1, 0.62890625: 1, 0.705078125: 1, 1.2337349397590363: 5, 3.657142857142857: 1, 0.646484375: 2, 0.72265625: 1, 1.8686131386861313: 1, 1.9320754716981132: 1, 0.826171875: 2, 1.2132701421800949: 4, 0.716796875: 1, 0.96484375: 1, 0.798828125: 2, 0.828125: 2, 0.78515625: 1, 0.724609375: 1, 1.8028169014084507: 2, 0.544921875: 1, 2.3486238532110093: 1, 2.1069958847736627: 1, 2.8287292817679557: 1, 1.841726618705036: 2, 2.1422594142259412: 2, 2.0813008130081303: 1, 2.0728744939271255: 1, 0.79296875: 1, 0.630859375: 1, 0.822265625: 2, 2.245614035087719: 1, 0.634765625: 1, 0.435546875: 1, 0.841796875: 2, 1.9176029962546817: 1})\n"
     ]
    }
   ],
   "source": [
    "# Example of how to call the analyze_image_sizes function\n",
    "root_dir = \"../Datasets/archive/images\"  # Path to the images directory\n",
    "\n",
    "image_sizes, aspect_ratios = analyze_image_sizes(root_dir)\n",
    "\n",
    "# Display results\n",
    "print(\"Image Sizes Distribution:\", image_sizes)\n",
    "print(\"Aspect Ratios Distribution:\", aspect_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
