{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R4 - Basic Classifiers and Decision Tree Implementation\n",
    "\n",
    "This notebook contains implementations for training and evaluating three basic classifiers:\n",
    "1. **Decision Tree Classifier**\n",
    "2. **k-Nearest Neighbors (k-NN)**\n",
    "3. **Naive Bayes Classifier**\n",
    "\n",
    "It also includes helper functions:\n",
    "- Methods to load and preprocess data.\n",
    "- Model evaluation techniques.\n",
    "- Visualization tools such as plotting the decision tree and confusion matrices.\n",
    "\n",
    "---\n",
    "\n",
    "## Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# common imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import for loading data\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Import for evaluating models and plotting consusion matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Imports for the models\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Loading\n",
    "\n",
    "This section defines functions for loading preprocessed datasets, including handling categorical variables through One-Hot Encoding and Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "def list_csv_files(directory):\n",
    "    \"\"\"\n",
    "    List all CSV files in the given directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory (str): Path to the directory.\n",
    "    \n",
    "    Returns:\n",
    "    - List of CSV filenames.\n",
    "    \"\"\"\n",
    "    return [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "def load_preprocessed_data(base_dir):\n",
    "    \"\"\"\n",
    "    Loads preprocessed training, validation, and test datasets.\n",
    "    \n",
    "    Args:\n",
    "        base_dir (str): Base directory containing the preprocessed datasets.\n",
    "    \n",
    "    Returns:\n",
    "        - X_train (DataFrame): Training features.\n",
    "        - X_valid (DataFrame): Validation features.\n",
    "        - X_test (DataFrame): Test features.\n",
    "        - y_train (Series): Training labels.\n",
    "        - y_valid (Series): Validation labels.\n",
    "        - y_test (Series): Test labels.\n",
    "    \"\"\"\n",
    "    # List available CSV files\n",
    "    available_files = list_csv_files(base_dir)\n",
    "    \n",
    "    required_files = ['X_train.csv', 'X_valid.csv', 'X_test.csv', 'y_train.csv', 'y_valid.csv', 'y_test.csv']\n",
    "    \n",
    "    # Check if all required files are present\n",
    "    missing_files = [f for f in required_files if f not in available_files]\n",
    "    if missing_files:\n",
    "        raise FileNotFoundError(f\"The following required files are missing in {base_dir}: {missing_files}\")\n",
    "    \n",
    "    # Load preprocessed datasets\n",
    "    X_train = pd.read_csv(f\"{base_dir}/X_train.csv\")\n",
    "    y_train = pd.read_csv(f\"{base_dir}/y_train.csv\")[\"target\"]\n",
    "    \n",
    "    X_valid = pd.read_csv(f\"{base_dir}/X_valid.csv\")\n",
    "    y_valid = pd.read_csv(f\"{base_dir}/y_valid.csv\")[\"target\"]\n",
    "    \n",
    "    X_test = pd.read_csv(f\"{base_dir}/X_test.csv\")\n",
    "    y_test = pd.read_csv(f\"{base_dir}/y_test.csv\")[\"target\"]\n",
    "    \n",
    "    # Identify categorical columns in features\n",
    "    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # One-Hot Encode categorical features\n",
    "    if categorical_cols:\n",
    "        # Apply OneHotEncoder to categorical columns\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        X_train_cat = encoder.fit_transform(X_train[categorical_cols])\n",
    "        X_valid_cat = encoder.transform(X_valid[categorical_cols])\n",
    "        X_test_cat = encoder.transform(X_test[categorical_cols])\n",
    "        \n",
    "        encoded_cols = encoder.get_feature_names_out(categorical_cols)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        X_train_cat = pd.DataFrame(X_train_cat, columns=encoded_cols, index=X_train.index)\n",
    "        X_valid_cat = pd.DataFrame(X_valid_cat, columns=encoded_cols, index=X_valid.index)\n",
    "        X_test_cat = pd.DataFrame(X_test_cat, columns=encoded_cols, index=X_test.index)\n",
    "        \n",
    "        # Drop original categorical columns and concatenate encoded columns\n",
    "        X_train = X_train.drop(columns=categorical_cols).reset_index(drop=True)\n",
    "        X_valid = X_valid.drop(columns=categorical_cols).reset_index(drop=True)\n",
    "        X_test = X_test.drop(columns=categorical_cols).reset_index(drop=True)\n",
    "        \n",
    "        X_train = pd.concat([X_train, X_train_cat], axis=1)\n",
    "        X_valid = pd.concat([X_valid, X_valid_cat], axis=1)\n",
    "        X_test = pd.concat([X_test, X_test_cat], axis=1)\n",
    "    \n",
    "    # Encode target variable if it's categorical\n",
    "    if y_train.dtype == 'object' or y_train.dtype.name == 'category':\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train = label_encoder.fit_transform(y_train)\n",
    "        y_valid = label_encoder.transform(y_valid)\n",
    "        y_test = label_encoder.transform(y_test)\n",
    "\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Helper Functions\n",
    "\n",
    "These helper functions facilitate common tasks like loading data, training models, evaluating performance, and plotting results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training Classifiers\n",
    "\n",
    "Below are functions to train different classifiers:\n",
    "- **Decision Tree**\n",
    "- **k-Nearest Neighbors**\n",
    "- **Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree model\n",
    "def train_decision_tree(X_train, y_train, max_depth=None):\n",
    "    \"\"\"\n",
    "    Trains a Decision Tree classifier.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features.\n",
    "        y_train: Training labels.\n",
    "        max_depth (int): Maximum depth of the tree. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained Decision Tree model.\n",
    "    \"\"\"\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Nearest Neighbors model\n",
    "def train_knn(X_train, y_train, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Train a k-NN model with the specified number of neighbors.\n",
    "    Args: X_train (features), y_train (labels), n_neighbors (number of neighbors to consider).\n",
    "    \n",
    "    Returns:\n",
    "        KNeighborsClassifier: The trained k-NN model.\n",
    "    \"\"\"\n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes model\n",
    "def train_naive_bayes(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a Gaussian Naïve Bayes classifier with given features and labels.\n",
    "    \n",
    "    Returns:\n",
    "        GaussianNB: The trained Gaussian Naïve Bayes model.\n",
    "    \"\"\"\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Evaluation function\n",
    "\n",
    "Evaluates a model and saves the results to a file inside a specific folder.\n",
    "\n",
    "**Args:**\n",
    "- model: Trained model.\n",
    "- X: Features for evaluation\n",
    "- y: True labels\n",
    "- model_name (str): Name of the model (for display purposes).\n",
    "- save_path (str): Path to save the evaluation report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate a model\n",
    "def evaluate_model(model, X, y, model_name, save_path=None):\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    report = classification_report(y, y_pred)\n",
    "    \n",
    "    evaluation_results = f\"{model_name} Model Evaluation:\\n\"\n",
    "    evaluation_results += f\"Accuracy: {accuracy:.4f}\\n\\n\"\n",
    "    evaluation_results += f\"Classification Report:\\n{report}\\n\"\n",
    "    \n",
    "    print(evaluation_results)\n",
    "    \n",
    "    if save_path:\n",
    "        with open(save_path, 'w') as f:\n",
    "            f.write(evaluation_results)\n",
    "        print(f\"{model_name} Model evaluation saved to {save_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plotting the decision tree\n",
    "\n",
    "Plots and saves the Decision Tree structure.\n",
    "\n",
    "**Args:**\n",
    "- model: Trained Decision Tree model.\n",
    "- feature_names (list): List of feature names.\n",
    "- class_names (list): List of class names.\n",
    "- save_path (str): Path to save the plot (without extension).\n",
    "- max_depth: Maximum depth to visualize (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the Decision Tree\n",
    "def plot_decision_tree(model, feature_names, class_names, save_path=None, max_depth=None):\n",
    "    \"\"\"\n",
    "    Plots and saves the Decision Tree structure.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Decision Tree model.\n",
    "        feature_names (list): List of feature names.\n",
    "        class_names (list): List of class names.\n",
    "        save_path (str): Path to save the plot (without extension).\n",
    "        max_depth: Maximum depth to visualize (optional)\n",
    "\n",
    "    Returns:\n",
    "        None (saves the plot to the specified path).\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(26, 10))\n",
    "    plot_tree(model, \n",
    "              feature_names=feature_names, \n",
    "              class_names=class_names, \n",
    "              max_depth=max_depth, \n",
    "              filled=True, \n",
    "              fontsize=10,\n",
    "              ax=ax, \n",
    "              rounded=True)\n",
    "    \n",
    "    plt.title(\"Decision Tree Visualization\", fontsize=24)\n",
    "    plt.subplots_adjust(left=0.025, right=0.995, top=0.94, bottom=0)  # Adjust space around the plot\n",
    "    \n",
    "    # Save the output plot as PNG file if save_path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(f\"{save_path}.png\")\n",
    "        print(f\"Decision tree plot saved to {save_path}.png\")\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plotting Confusion Matrix\n",
    "\n",
    "This function visualizes the confusion matrix for the Naive Bayes model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names, output_path):\n",
    "    \"\"\"\n",
    "    Plot and save the confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        y_true (pd.Series): True labels.\n",
    "        y_pred (pd.Series): Predicted labels.\n",
    "        class_names (list): List of class names.\n",
    "        output_path (str): Path to save the confusion matrix plot.\n",
    "    \n",
    "    Returns:\n",
    "        None: This function does not return any value. It saves the confusion matrix plot to the specified output path.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cm_display.plot(cmap='Blues', ax=ax, values_format='d')\n",
    "    plt.title('Confusion Matrix - Naive Bayes')\n",
    "    plt.savefig(output_path)\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Plot KNN model accuracy for different values of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_knn_accuracy(results, best_k, results_dir, dataset_name):\n",
    "    k_values = [result[0] for result in results]\n",
    "    accuracies = [result[1] for result in results]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_values, accuracies, marker='o', linestyle='-', color='b')\n",
    "    plt.title(f'Accuracy of k-NN for Different k Values (Best k={best_k})')\n",
    "    plt.xlabel('k (Number of Neighbors)')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.grid(True)\n",
    "    knn_plot_path = os.path.join(results_dir, f\"{dataset_name}_2.knn_accuracy_plot.png\")\n",
    "    plt.savefig(knn_plot_path)\n",
    "    print(f\"KNN accuracy plot saved to {knn_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Finding the Best `k` for k-Nearest Neighbors (k-NN)\n",
    "\n",
    "This function iterates over different values of `k` (from 1 to 20) to determine the one with the highest validation accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k_for_knn(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Find the best k for k-NN and return the best k and accuracy.\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training labels.\n",
    "        X_valid (pd.DataFrame): Validation features.\n",
    "        y_valid (pd.Series): Validation labels.\n",
    "    \n",
    "    Returns:\n",
    "        int: The best k value.\n",
    "    \"\"\"\n",
    "    best_k = None\n",
    "    best_accuracy = 0\n",
    "    results = []\n",
    "\n",
    "    print(\"\\nFinding the best k for k-NN...\")\n",
    "    for k in range(1, 21): # k values from 1 to 20\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_valid)\n",
    "        accuracy = accuracy_score(y_valid, y_pred)\n",
    "        results.append((k, accuracy)) # Store the results for each k\n",
    "        print(f\"k={k}: Validation Accuracy = {accuracy:.4f}\") # Print the accuracy for each k\n",
    "        if accuracy > best_accuracy: # Update the best k if the current k is better\n",
    "            best_k = k\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "    return best_k, best_accuracy, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Creating Results Directory\n",
    "\n",
    "A helper function to create directories for saving evaluation results and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_directory(base_dir: str, dataset_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Create results directory for the specific dataset.\n",
    "    \n",
    "    Args:\n",
    "        base_dir (str): The base directory where the results directory will be created.\n",
    "        dataset_name (str): The name of the dataset for which the results directory is created.\n",
    "    \n",
    "    Returns:\n",
    "        str: The path to the created results directory.\n",
    "    \"\"\"\n",
    "    script_dir = os.getcwd()  # Get the current working directory\n",
    "    results_base_dir = os.path.join(script_dir, \"R4_Results\", dataset_name)\n",
    "    os.makedirs(results_base_dir, exist_ok=True)\n",
    "    return results_base_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Model selection and handling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letting the user choose a model\n",
    "def get_model_choice():\n",
    "    print(\"\\nChoose a model to train:\")\n",
    "    print(\"1. Decision Tree\")\n",
    "    print(\"2. k-Nearest Neighbors\")\n",
    "    print(\"3. Naive Bayes\")\n",
    "    choice = input(\"Enter your choice (1/2/3): \").strip()\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_decision_tree(X_train, y_train, X_valid, y_valid, results_dir, dataset_name):\n",
    "    # Train Decision Tree model\n",
    "    model = train_decision_tree(X_train, y_train, max_depth=10)\n",
    "\n",
    "    # Visualize the decision tree\n",
    "    feature_names = list(X_train.columns)\n",
    "    unique_classes = sorted(set(y_train)) # Get unique classes in the target variable\n",
    "    class_names = [f'Class {cls}' for cls in unique_classes] # Create class names for the plot\n",
    "    plot_file_path = os.path.join(results_dir, f\"{dataset_name}_1.decision_tree_plot\")\n",
    "    plot_decision_tree(model, feature_names, class_names, plot_file_path, max_depth=3) # Plot the decision tree\n",
    "\n",
    "    # Save Decision Tree model evaluation to a separate file\n",
    "    evaluation_output_path = os.path.join(results_dir, f\"{dataset_name}_1.decision_tree_model_evaluation.txt\")\n",
    "    evaluate_model(model, X_valid, y_valid, \"Decision Tree\", evaluation_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_knn(X_train, y_train, X_valid, y_valid, results_dir, dataset_name):\n",
    "    # Find the best k for k-NN\n",
    "    best_k, best_accuracy, results = find_best_k_for_knn(X_train, y_train, X_valid, y_valid)\n",
    "\n",
    "    # Save best k results\n",
    "    best_k_path = os.path.join(results_dir, f\"{dataset_name}_2.best_k_for_knn.txt\")\n",
    "    with open(best_k_path, 'w') as f:\n",
    "        f.write(f\"Best k: {best_k}\\n\")\n",
    "        f.write(f\"Validation Accuracy: {best_accuracy:.4f}\\n\")\n",
    "        f.write(\"All k results:\\n\")\n",
    "        for k, acc in results:\n",
    "            f.write(f\"k={k}: Validation Accuracy = {acc:.4f}\\n\")\n",
    "\n",
    "    print(f\"\\nBest k value saved to {best_k_path}\")\n",
    "\n",
    "    # Train k-Nearest Neighbors model with the best k (from the range 1-20)\n",
    "    model = train_knn(X_train, y_train, n_neighbors=best_k)\n",
    "\n",
    "    # Save KNN model evaluation to a separate file\n",
    "    evaluation_output_path = os.path.join(results_dir, f\"{dataset_name}_2.knn_model_evaluation.txt\")\n",
    "    evaluate_model(model, X_valid, y_valid, \"k-Nearest Neighbors\", evaluation_output_path)\n",
    "\n",
    "    # Plot KNN model accuracy for different values of k\n",
    "    plot_knn_accuracy(results, best_k, results_dir, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_naive_bayes(X_train, y_train, X_valid, y_valid, results_dir, dataset_name):\n",
    "    # Train Naive Bayes model\n",
    "    model = train_naive_bayes(X_train, y_train)\n",
    "\n",
    "    # Save Naive Bayes model evaluation to a separate file\n",
    "    evaluation_output_path = os.path.join(results_dir, f\"{dataset_name}_3.naive_bayes_model_evaluation.txt\")\n",
    "    evaluate_model(model, X_valid, y_valid, \"Naive Bayes\", evaluation_output_path)\n",
    "\n",
    "    # Plot confusion matrix for Naive Bayes model\n",
    "    y_pred = model.predict(X_valid)  # Predict the validation set\n",
    "    unique_classes = sorted(set(y_train)) # Get unique classes in the target variable\n",
    "    class_names = [f'Class {cls}' for cls in unique_classes] # Create class names for the plot\n",
    "    cm_plot_path = os.path.join(results_dir, f\"{dataset_name}_3.naive_bayes_confusion_matrix.png\")\n",
    "    plot_confusion_matrix(y_valid, y_pred, class_names, cm_plot_path)\n",
    "\n",
    "    print(f\"Confusion Matrix for Naive Bayes saved to {cm_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Main Program Execution\n",
    "\n",
    "The main function allows the user to:\n",
    "1. Select the dataset.\n",
    "2. Choose a classifier to train.\n",
    "\n",
    "Then Evaluate and save results using the helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Automatically get the base directory for preprocessed data\n",
    "    base_dir = os.path.join(os.pardir, 'Datasets', 'preprocessed_data')\n",
    "    \n",
    "    # Get the specific data directory from the user\n",
    "    print(\"Choose the dataset to load:\")\n",
    "    print(\"1. Delivery Dataset\")\n",
    "    print(\"2. Restaurant Dataset\")\n",
    "\n",
    "    choice = input(\"Enter your choice (1/2): \").strip()\n",
    "    if choice == '1':\n",
    "        dataset_dir = os.path.join(base_dir, 'delivery')\n",
    "    elif choice == '2':\n",
    "        dataset_dir = os.path.join(base_dir, 'restaurant')\n",
    "    else:\n",
    "        print(\"Invalid choice. Exiting...\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(dataset_dir):\n",
    "        print(f\"The directory {dataset_dir} does not exist. Please check your input.\")\n",
    "        return\n",
    "\n",
    "    # Load preprocessed data\n",
    "    try:\n",
    "        X_train, X_valid, X_test, y_train, y_valid, y_test = load_preprocessed_data(dataset_dir)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        return\n",
    "    \n",
    "    # Extract dataset name from the input directory\n",
    "    dataset_name = os.path.basename(dataset_dir.rstrip('/'))\n",
    "    results_dir = create_results_directory(base_dir, dataset_name)\n",
    "\n",
    "    choice = get_model_choice()\n",
    "    if choice == '1':\n",
    "        handle_decision_tree(X_train, y_train, X_valid, y_valid, results_dir, dataset_name)\n",
    "    \n",
    "    elif choice == '2':\n",
    "        handle_knn(X_train, y_train, X_valid, y_valid, results_dir, dataset_name)\n",
    "    \n",
    "    elif choice == '3':\n",
    "        handle_naive_bayes(X_train, y_train, X_valid, y_valid, results_dir, dataset_name)\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid choice. Exiting...\")\n",
    "        return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
